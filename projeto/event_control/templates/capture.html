{% extends 'base.html' %}
{% load static %}

{% block head %}
    <script defer src="{% static 'js/face-api.min.js' %}" onload="initFaceApi()"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            width: 100vw;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        canvas {
            position: absolute;

        }
    </style>
{% endblock %}

{% block body %}
<div class="flex flex-col">
    {% if messages %}
        {% for message in messages %}
            <div class="toast bg-zinc-700 border border-gray-300 shadow-lg rounded-lg p-4 mb-4 flex items-start space-x-4">
                <div class="flex-shrink-0">
                    {% if message.tags == 'success' %}
                        <svg class="w-6 h-6 text-green-500" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                    {% elif message.tags == 'error' %}
                        <svg class="w-6 h-6 text-red-600" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path></svg>
                    {% endif %}
                </div>
                <div class="flex-1">
                    <p class="text-lg font-medium {% if message.tags == 'success' %}text-green-700{% elif message.tags == 'error' %}text-red-600{% endif %}">
                        {{ message.message }}
                    </p>
                </div>
                <div class="ml-4 flex-shrink-0">
                    <button type="button" class="text-gray-400 hover:text-gray-600" aria-label="Close" onclick="this.closest('.toast').remove()">
                        <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path></svg>
                    </button>
                </div>
            </div>
        {% endfor %}
    {% endif %}
    <video id="video" width="720" height="560" autoplay muted></video>
    <form id="faceForm" method="POST" enctype="multipart/form-data" action="{% url 'capture' request.resolver_match.kwargs.id %}">
        {% csrf_token %}
        <input type="hidden" name="face_image" id="face_image">
    </form>
</div>
{% endblock %}

{% block script %}
<script>
    let isFaceRecognized = false;
    const video = document.querySelector("#video");
    const form = document.getElementById("faceForm");
    const hiddenInput = document.getElementById("face_image");
    const toast = document.querySelector(".toast")
    if(toast){
        setTimeout(() => {
            toast.remove()
        }, 2000)
    }
    function initFaceApi() {
        Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri('/static/models'),
            faceapi.nets.faceLandmark68Net.loadFromUri('/static/models'),
            faceapi.nets.faceRecognitionNet.loadFromUri('/static/models'),
            faceapi.nets.faceExpressionNet.loadFromUri('/static/models'),
        ]).then(startVideo);

        function startVideo() {
            navigator.getUserMedia(
                { video: {} },
                stream => video.srcObject = stream,
                err => console.error(err)
            );
        }

        video.addEventListener('play', () => {
            const canvas = faceapi.createCanvasFromMedia(video)
            document.body.append(canvas)
            const displaySize = { width: video.width, height: video.height }
            faceapi.matchDimensions(canvas, displaySize)
            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video,
                    new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks()
                    .withFaceExpressions()
                    const resizedDetections = faceapi.resizeResults(detections, displaySize)
                    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)
                    faceapi.draw.drawDetections(canvas, resizedDetections)
                    if (detections.length > 0 && resizedDetections[0].detection._score >= 0.80 && !isFaceRecognized){
                        isFaceRecognized = true;
                        const faceCanvas = document.createElement('canvas')
                        faceCanvas.width = video.width
                        faceCanvas.height = video.height
                        const ctx = faceCanvas.getContext('2d')
                        ctx.drawImage(video, 0, 0, faceCanvas.width, faceCanvas.height)

                        const faceImageData = faceCanvas.toDataURL('image/png')
                        hiddenInput.value = faceImageData
                        form.submit()
                    }
            }, 100)
        })
    }
</script>
{% endblock %}